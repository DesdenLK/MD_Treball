{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn import model_selection as cv\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, cross_validate\n",
    "import sklearn.neighbors as nb\n",
    "from sklearn.ensemble import (\n",
    "    AdaBoostClassifier,\n",
    "    BaggingClassifier,\n",
    "    ExtraTreesClassifier,\n",
    "    RandomForestClassifier,\n",
    "    VotingClassifier,    \n",
    "    GradientBoostingClassifier\n",
    ")\n",
    "\n",
    "\n",
    "import sklearn\n",
    "import sklearn.datasets as ds\n",
    "import sklearn.model_selection as cv\n",
    "import sklearn.neighbors as nb\n",
    "from sklearn.model_selection import (\n",
    "    StratifiedKFold,\n",
    "    cross_val_score,\n",
    "    GridSearchCV,\n",
    "    validation_curve,\n",
    "    StratifiedShuffleSplit\n",
    ")\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler,\n",
    "    MinMaxScaler,\n",
    ")\n",
    "from sklearn.svm import (\n",
    "    LinearSVC,\n",
    "    SVC,\n",
    ")\n",
    "from sklearn.ensemble import (\n",
    "    ExtraTreesClassifier,\n",
    "    AdaBoostClassifier,\n",
    "    BaggingClassifier,\n",
    ")\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import (\n",
    "    mutual_info_classif,\n",
    "    SelectKBest\n",
    ")\n",
    "\n",
    "from statsmodels.stats.proportion import proportion_confint\n",
    "from statsmodels.stats.contingency_tables import mcnemar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from statsmodels.stats.contingency_tables import mcnemar\n",
    "\n",
    "def get_contingency_table(Y, ground_truth, model_1, model_2):\n",
    "    contingency_table = [[0, 0], [0, 0]]\n",
    "    Y_ = Y.copy()\n",
    "    model_1_correct = Y_.apply(lambda row: int(row[ground_truth] == row[model_1]), axis=1)\n",
    "    model_2_correct = Y_.apply(lambda row: int(row[ground_truth] == row[model_2]), axis=1)\n",
    "\n",
    "    contingency_table[0][0] = ((model_1_correct == 1) & (model_2_correct == 1)).sum()\n",
    "    contingency_table[0][1] = ((model_1_correct == 1) & (model_2_correct == 0)).sum()\n",
    "    contingency_table[1][0] = ((model_1_correct == 0) & (model_2_correct == 1)).sum()\n",
    "    contingency_table[1][1] = ((model_1_correct == 0) & (model_2_correct == 0)).sum()\n",
    "\n",
    "    return np.array(contingency_table)\n",
    "\n",
    "def mcnemar_test(contingency_table, significance=0.05):\n",
    "    print(\"Contingency Table\")\n",
    "    print(contingency_table)\n",
    "    test = mcnemar(contingency_table, exact=False, correction=True)\n",
    "    print(\"P value:\", test.pvalue)\n",
    "    if test.pvalue <= significance:\n",
    "        print(\"Reject Null Hypothesis\")\n",
    "        print(\"Conclusion: Models have statistically different error rates\")\n",
    "        if contingency_table[0][1] > contingency_table[1][0]:\n",
    "            print(\"model_1 is better\")\n",
    "        elif contingency_table[0][1] < contingency_table[1][0]:\n",
    "            print(\"model_2 is better\")\n",
    "        else:\n",
    "            print(\"Are equally good\")\n",
    "    else:\n",
    "        print(\"Accept Null Hypothesis\")\n",
    "        print(\"Conclusion: Models do not have statistically different error rates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoking_dataset = pd.read_csv(filepath_or_buffer=\"Dataset/Smoking_preprocessed.csv\")\n",
    "normalized_dataset = pd.read_csv(filepath_or_buffer=\"Dataset/Normalized_Smoking.csv\")\n",
    "standardized_dataset = pd.read_csv(filepath_or_buffer=\"Dataset/Standardized_Smoking.csv\")\n",
    "\n",
    "X = smoking_dataset.iloc[:, :-1]\n",
    "y = smoking_dataset.loc[:, \"smoking\"]\n",
    "\n",
    "X_norm = normalized_dataset.iloc[:, :-1]\n",
    "y_norm = normalized_dataset.loc[:, \"smoking\"]\n",
    "\n",
    "X_standar = standardized_dataset.iloc[:, :-1]\n",
    "y_standar = standardized_dataset.loc[:, \"smoking\"]\n",
    "\n",
    "(X_train, X_test,  y_train, y_test) = cv.train_test_split(X, y, test_size = .3, random_state = 1)\n",
    "(X_norm_train, X_norm_test,  y_norm_train, y_norm_test) = cv.train_test_split(X_norm, y_norm, test_size = .3, random_state = 1)\n",
    "(X_standar_train, X_standar_test,  y_standar_train, y_standar_test) = cv.train_test_split(X_standar, y_standar, test_size = .3, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {'max_depth': 42, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
    "\n",
    "cdt= DecisionTreeClassifier(\n",
    "    criterion = \"entropy\", \n",
    "    min_samples_split = best_params[\"min_samples_split\"],\n",
    "    min_impurity_decrease = best_params[\"min_impurity_decrease\"],\n",
    "    min_samples_leaf = best_params[\"min_samples_leaf\"],\n",
    "    max_depth = best_params[\"max_depth\"]    \n",
    ")\n",
    "clf = cdt.fit(X_train, y_train)\n",
    "predDt = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "undersampler = RandomUnderSampler(sampling_strategy=\"majority\", random_state=1)\n",
    "X_standar_train_Bg, y_standar_train_Bg = undersampler.fit_resample(X_standar_train, y_standar_train)\n",
    "\n",
    "dt = DecisionTreeClassifier(\n",
    "    criterion=\"entropy\",\n",
    "    min_samples_split=2,\n",
    "    min_impurity_decrease=0.0,\n",
    "    min_samples_leaf=1,\n",
    "    max_depth=42\n",
    ")\n",
    "\n",
    "model = BaggingClassifier(\n",
    "        estimator = dt,\n",
    "        n_estimators = 50,\n",
    "        max_features=0.35,\n",
    "        random_state=1,\n",
    "    )\n",
    "\n",
    "clf = model.fit(X_standar_train_Bg, y_standar_train_Bg)\n",
    "predsBg = clf.predict(X_standar_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "undersampler = RandomUnderSampler(sampling_strategy=\"majority\", random_state=1)\n",
    "X_standar_train_RF, y_standar_train_RF = undersampler.fit_resample(X_standar_train, y_standar_train)\n",
    "\n",
    "random_forest_classifier = RandomForestClassifier(\n",
    "    n_estimators = 50,\n",
    "    max_features = 0.35,\n",
    "    random_state=1\n",
    ")\n",
    "\n",
    "clf = random_forest_classifier.fit(X_standar_train_RF, y_standar_train_RF)\n",
    "predsRF = clf.predict(X_standar_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = RandomUnderSampler(sampling_strategy='majority', random_state=1)\n",
    "X_standar_train_SVM, y_standar_train_SVM = sampler.fit_resample(X_standar_train, y_standar_train) # Compensate for data unbalance\n",
    "\n",
    "knc = SVC(kernel='linear', C=1.0)\n",
    "knc.fit(X_standar_train_SVM, y_standar_train_SVM)\n",
    "predsSVM = knc.predict(X_standar_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "knc = nb.KNeighborsClassifier(n_neighbors=27, weights='distance')\n",
    "knc = knc.fit(X_norm_train, y_norm_train)\n",
    "predsKNN = knc.predict(X_norm_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive-Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "undersampler = RandomUnderSampler(sampling_strategy='majority', random_state=1)\n",
    "\n",
    "def filterp(th,ProbClass1):\n",
    "    \"\"\"Given a threshold \"th\" and a set of probabilities of belonging to class 1 \"ProbClass1\", \n",
    "    return predictions.\"\"\" \n",
    "    y = np.zeros(ProbClass1.shape[0])\n",
    "    for i,v in enumerate(ProbClass1):\n",
    "        if ProbClass1[i]>th:\n",
    "            y[i]=1\n",
    "    return y  \n",
    "\n",
    "X_under_train, y_under_train  = undersampler.fit_resample(X_standar_train, y_standar_train)\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_under_train, y_under_train)\n",
    "\n",
    "# Obtain probabilities for data on test set\n",
    "probs = clf.predict_proba(X_standar_test)\n",
    "\n",
    "# Generate predictions using probabilities and threshold found on 10 folds cross-validation\n",
    "predsNB = filterp(0.009984,probs[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees vs Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contingency Table\n",
      "[[11035  1924]\n",
      " [ 1874  1816]]\n",
      "P value: 0.4265586928944306\n",
      "Accept Null Hypothesis\n",
      "Conclusion: Models do not have statistically different error rates\n"
     ]
    }
   ],
   "source": [
    "Y = pd.DataFrame(y_test.copy())\n",
    "Y[\"model_1\"] = predDt\n",
    "Y[\"model_2\"] = predsBg\n",
    "\n",
    "mcnemar_test(get_contingency_table(Y, 'smoking', 'model_1', 'model_2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree vs Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contingency Table\n",
      "[[11225  1734]\n",
      " [ 1869  1821]]\n",
      "P value: 0.025588316017032677\n",
      "Reject Null Hypothesis\n",
      "Conclusion: Models have statistically different error rates\n",
      "model_2 is better\n"
     ]
    }
   ],
   "source": [
    "Y = pd.DataFrame(y_test.copy())\n",
    "Y[\"model_1\"] = predDt\n",
    "Y[\"model_2\"] = predsRF\n",
    "\n",
    "mcnemar_test(get_contingency_table(Y, 'smoking', 'model_1', 'model_2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging vs Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contingency Table\n",
      "[[12179   730]\n",
      " [  915  2825]]\n",
      "P value: 5.715598308361687e-06\n",
      "Reject Null Hypothesis\n",
      "Conclusion: Models have statistically different error rates\n",
      "model_2 is better\n"
     ]
    }
   ],
   "source": [
    "Y = pd.DataFrame(y_test.copy())\n",
    "Y[\"model_1\"] = predsBg\n",
    "Y[\"model_2\"] = predsRF\n",
    "\n",
    "mcnemar_test(get_contingency_table(Y, 'smoking', 'model_1', 'model_2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM vs Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contingency Table\n",
      "[[11184   445]\n",
      " [ 1910  3110]]\n",
      "P value: 6.240888016339758e-200\n",
      "Reject Null Hypothesis\n",
      "Conclusion: Models have statistically different error rates\n",
      "model_2 is better\n"
     ]
    }
   ],
   "source": [
    "Y = pd.DataFrame(y_test.copy())\n",
    "Y[\"model_1\"] = predsSVM\n",
    "Y[\"model_2\"] = predsRF\n",
    "\n",
    "mcnemar_test(get_contingency_table(Y, 'smoking', 'model_1', 'model_2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive-Bayes vs Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contingency Table\n",
      "[[11138   491]\n",
      " [ 1956  3064]]\n",
      "P value: 1.7128950776428786e-192\n",
      "Reject Null Hypothesis\n",
      "Conclusion: Models have statistically different error rates\n",
      "model_2 is better\n"
     ]
    }
   ],
   "source": [
    "Y = pd.DataFrame(y_test.copy())\n",
    "Y[\"model_1\"] = predsNB\n",
    "Y[\"model_2\"] = predsRF\n",
    "\n",
    "mcnemar_test(get_contingency_table(Y, 'smoking', 'model_1', 'model_2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN vs Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contingency Table\n",
      "[[11763  1550]\n",
      " [ 1331  2005]]\n",
      "P value: 4.876153060712708e-05\n",
      "Reject Null Hypothesis\n",
      "Conclusion: Models have statistically different error rates\n",
      "model_1 is better\n"
     ]
    }
   ],
   "source": [
    "Y = pd.DataFrame(y_test.copy())\n",
    "Y[\"model_1\"] = predsKNN\n",
    "Y[\"model_2\"] = predsRF\n",
    "\n",
    "mcnemar_test(get_contingency_table(Y, 'smoking', 'model_1', 'model_2'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
